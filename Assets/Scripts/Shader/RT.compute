// Each #kernel tells which function to compile; you can have many kernels
#pragma enable_d3d11_debug_symbols
//#pragma kernel CSMain
#pragma kernel ShadowPass
//#pragma kernel ReflectionPass
//#pragma kernel AOPass

#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Common.hlsl"
//#include "Library/PackageCache/com.unity.render-pipelines.core@7.4.3/ShaderLibrary/Random.hlsl"
//#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Packing.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/ShaderLibrary/ShaderVariables.hlsl"
//#include "Packages/com.unity.render-pipelines.high-definition/Runtime/Material/Builtin/BuiltinData.hlsl"

#include "Packages/com.unity.render-pipelines.high-definition/Runtime/Material/NormalBuffer.hlsl"

#include "tracingUtils.hlsl"

RWTexture2D<float4> texOut;

Texture2D<float4> skybox;
SamplerState sampler_skybox;

float4 directionalLight; // w is the intensity

StructuredBuffer<Sphere> spheres;

StructuredBuffer<Mesh> meshes;
StructuredBuffer<float3> meshVertices;
StructuredBuffer<int> meshEbo;
StructuredBuffer<LBVH> bvhTree;

float4x4 cameraToWorld;
float4x4 cameraInvProj;

//random displacement
float2 pixelOffset;

float2 _pixel;

Ray CreateCameraRay(float2 uv)
{
    // Transform the camera origin to world space
    // (0, 0, 0) in localCameraSpace to world
    float3 origin = mul(cameraToWorld, float4(0.0f, 0.0f, 0.0f, 1.0f)).xyz;
    
    // Invert the perspective projection of the view-space position
    //view space to localCameraSpace
    float3 direction = mul(cameraInvProj, float4(uv, 0.0f, 1.0f)).xyz;
    // Transform the direction from camera to world space and normalize
    direction = mul(cameraToWorld, float4(direction, 0.0f)).xyz;
    direction = normalize(direction);
    Ray r;
    r.a = origin;
    r.direction = direction;
    r.energy = (float3)1;
    r.invDir = 1 / direction;
    return r;
}

float3x3 GetTangentSpace(float3 normal)
{
    // Choose a helper vector for the cross product
    float3 helper = float3(1, 0, 0);
    if (abs(normal.x) > 0.99f)
        helper = float3(0, 0, 1);
        
    // Generate vectors
    float3 tangent = normalize(cross(normal, helper));
    float3 binormal = normalize(cross(normal, tangent));
    return float3x3(tangent, binormal, normal);
}

float3 SampleHemisphere(float3 normal, float alpha)
{
    //https://blog.thomaspoulet.fr/uniform-sampling-on-unit-hemisphere/
    // Uniformly sample hemisphere direction
    float cosTheta = pow(rand(_pixel), 1 / (1 + alpha));
    float sinTheta = sqrt(1.0f - cosTheta * cosTheta);
    float phi = 2 * PI * rand(_pixel);
    
    float3 tangentSpaceDir = float3(cos(phi) * sinTheta, sin(phi) * sinTheta, cosTheta);
    
    // Transform direction to world space
    return mul(tangentSpaceDir, GetTangentSpace(normal));
}

bool TraverseTreeForHit(Ray r)
{
    int stackNodes[32];
    
    //This is useful to know which branch to choose 
    // if the axis splits is neg in the ray then we take the right hand branch (second child)
    // we can do this because we ordered the splitting during the construction
    bool isDirNeg[] = {r.invDir.x < 0, r.invDir.y < 0, r.invDir.z < 0};

    int toVisitOffset = 0, currentNodeIndex = 0;
    LBVH node = bvhTree[currentNodeIndex];
    while (true)
    {
        node = bvhTree[currentNodeIndex];

        if (rayBoxIntersection(node.minBox, node.maxBox, r))
        {
            int primitives = (node.primAndAxis >> 16);
            if ( primitives > 0) //it's a leaf
            {

                //return true;
                //For now we have only one primitive in the leaf so we can simplify things
               // float4x4 localToWorldMatrix = meshes[node.offset].localToWorld;

                for (uint ite = 0; ite < primitives; ++ite)
                {
                    uint mesh = node.offset + ite;
                    int count = meshes[mesh].eboCount;
                    float3 a,b,c;
                    for(uint i = meshes[mesh].eboOffset; i < count; i+=3)
                    {
                        a = meshVertices[meshEbo[i]];
                        b = meshVertices[meshEbo[i + 1]];
                        c = meshVertices[meshEbo[i + 2]];

                       // a = meshVertices[i];
                       // b = (meshVertices[i + 1]);
                       // c = (meshVertices[i + 2]);
                        
                       //  a = mul(localToWorldMatrix, a);
                      //   b = mul(localToWorldMatrix, b);
                      //  c = mul(localToWorldMatrix, c);

                    
                        if(TriangleIntersectionHit(r, a, b, c))
                            return true;
                        
                    }
                }
               
                
                if (toVisitOffset == 0) return false;
                currentNodeIndex = stackNodes[--toVisitOffset];
            }
            else
            {
                if (isDirNeg[(node.primAndAxis & 3)])
                {
                    stackNodes[toVisitOffset++] = currentNodeIndex + 1; //left hand child
                    currentNodeIndex = node.offset;
                }
                else
                {
                    stackNodes[toVisitOffset++] = node.offset;
                    currentNodeIndex = currentNodeIndex + 1;
                }
            }
        }
        else
        {
            if (toVisitOffset == 0) return false;
            currentNodeIndex = stackNodes[--toVisitOffset];
        }
    }

    return false;
}


bool Trace(Ray r)
{
    RayHit hit;
    for(uint k = 0; k < 1; ++k)
    {
        if(sphereIntersection(r, hit, spheres[k], _ProjectionParams.y, _ProjectionParams.z))
            return true;
    }

    return TraverseTreeForHit(r);
}

float3 Shade(inout Ray r, RayHit hit)
{
    if(hit.alpha > _ProjectionParams.z) //we've hit nothing
    {
        //switching to spherical coordinates to sample the skybox
        float theta = acos(r.direction.y) / -PI;
        float phi = atan2(r.direction.x, -r.direction.z) / -PI * 0.5f;
        
        r.energy = 0;

        return skybox.SampleLevel(sampler_skybox, float2(phi, theta), 0);
    }
    else
    {   
        //hit.color = min(1.0f - hit.specular, hit.color);
        //we average the spec and diff, to see which will be used
        float specChance = dot(hit.specular, 1.0f / 3.0f);
        float diffChance = dot(hit.color, 1.0f / 3.0f);
        
        //transform our chances to [0, 1]
        //used for probability and weight
        float sum = specChance + diffChance;
        specChance /= sum;
        diffChance /= sum;
        
        float random = rand(_pixel);
        
        r.a = hit.position + hit.normal + 0.001f; //just a bit off the surface, +.001f for ieee inaccuracy
        
        if(random < specChance)
        {
            float alpha = SmoothnessToPhongAlpha(hit.smoothness);
            //specular reflection
             r.direction = SampleHemisphere(reflect(r.direction, hit.normal), alpha);
             float fs = (alpha + 2) / (alpha + 1);
             r.energy *= (1.0f / specChance) * hit.specular * saturate(dot(hit.normal, r.direction) * fs);
        }
        else if(diffChance > 0 && random < specChance + diffChance)
        {
            r.direction = SampleHemisphere(hit.normal, 1.0f);
            r.energy *= (1.0f / diffChance) * hit.color;
        }
        else
            r.energy = 0.0f;
        
        return hit.emission;
    }
}


//This is used to compute shadows
[numthreads(8, 8, 1)]
void ShadowPass(uint3 id : SV_DispatchThreadID)
{
    uint texSizeX, texSizeY;
    texOut.GetDimensions(texSizeX, texSizeY);

    float2 uv = (id.xy) / float2(texSizeX, texSizeY);
    
    float2 uvClip = uv * 2.0f - 1.0f;
    uint2 positionSS = uv * _ScreenSize.xy;
    
    float depth = SampleCameraDepth(uv);
    float linearDepth = Linear01Depth(depth, _ZBufferParams);
    
    //sky here, depth is [1, 0]
    if(linearDepth == 1.0f)
    {
        texOut[id.xy] = (float4)1.0f;
        return;
    }
    
    //mapping to [-1, 1] clip space;
    depth = abs(depth - 1.0f) * 2.0f - 1.0f;
    
    float4 cs = float4(uvClip, depth, 1.0f);
    float4 viewPos = mul(cameraInvProj, cs);
    
    //perspective division
    viewPos /= viewPos.w; 
    
    float3 worldPos = mul(cameraToWorld, viewPos);
    
    RayHit hit;
    hit.alpha = _ProjectionParams.z + 1;
    
    NormalData normalData;
    DecodeFromNormalBuffer(positionSS, normalData);
    float3 N = normalData.normalWS;
    
    Ray r;
    
    r.a = worldPos + (N * 0.1f);//adding bias
    r.direction = -directionalLight; 
    r.invDir = normalize(1 / -directionalLight);
    r.energy = (float3)1;//change this according to the material we start on
    
    //We can optimize this by stopping at the first hit
    //beware of alpha materials (leafs)
    bool hitSomething = Trace(r);
    
    //packing shadows in x and reflections in y,z,w
    texOut[id.xy] = float4(!hitSomething, 0.0f, 0.0f, 0.0f);
}


[numthreads(16, 16, 1)]
void AOPass(uint3 id : SV_DispatchThreadID)
{
    uint texSizeX, texSizeY;
    texOut.GetDimensions(texSizeX, texSizeY);

    float2 uv = (id.xy) / float2(texSizeX, texSizeY);
    
    float2 uvClip = uv * 2.0f - 1.0f;
    uint2 positionSS = uv * _ScreenSize.xy;
    
    float depth = SampleCameraDepth(uv);
    float linearDepth = Linear01Depth(depth, _ZBufferParams);
    
    //sky here, depth is [1, 0]
    if(linearDepth == 1.0f)
    {
        return;
    }
    
    //mapping to [-1, 1] clip space;
    depth = abs(depth - 1.0f) * 2.0f - 1.0f;
    
    float4 cs = float4(uvClip, depth, 1.0f);
    float4 viewPos = mul(cameraInvProj, cs);
    
    //perspective division
    viewPos /= viewPos.w; 
    
    float3 worldPos = mul(cameraToWorld, viewPos);
    
    RayHit hit;
    hit.alpha = _ProjectionParams.z + 1;
    
    NormalData normalData;
    DecodeFromNormalBuffer(positionSS, normalData);
    float3 N = normalData.normalWS;
    
    Ray r;
    float result = 0.0f;
    
    for(uint i = 0; i < 1; i++)
    {
        r.a = worldPos + (N * 0.1f);//adding bias
        r.direction = SampleHemisphere(N, SmoothnessToPhongAlpha(0.5f)); 
        r.invDir = normalize(1 / N);
        r.energy = (float3)1;

        result += !Trace(r);
    }

    //result /= 2.0f;
    

    //packing shadows in x and reflections in y,z,w
    //texOut[id.xy] = float4(0, 0.0f, 0.0f, 0.0f);
}

/*[numthreads(8,8,1)]
void CSMain (uint3 id : SV_DispatchThreadID)
{
    uint texSizeX, texSizeY;
    texOut.GetDimensions(texSizeX, texSizeY);
    uint stride;
    spheres.GetDimensions(spheresCount, stride);

    meshEbo.GetDimensions(eboCount, stride);
    meshes.GetDimensions(meshCount, stride);
    
    float2 cameraSpace;
    
    _pixel = id.xy;
    
    // [-1;1]
    cameraSpace = (id.xy + pixelOffset) / float2(texSizeX, texSizeY) * 2.0f - 1.0f;
    
    //Change this with the deferred data
    //Ray r = CreateCameraRay(cameraSpace);
    
    //and this also
    RayHit hit;
    
    float2 uv = id.xy / float2(texSizeX, texSizeY);
    float3 color = SAMPLE_TEXTURE2D_X_LOD(_ColorPyramidTexture, s_linear_repeat_sampler, uv, 0).rgb;
    //float3 color = (float3)0;
    
    uint2 positionSS = uv * _ScreenSize.xy;
    //float depth = Linear01Depth(LoadCameraDepth(positionSS), _ZBufferParams);
    float depth = (LoadCameraDepth(positionSS));
    
    float4 cs = float4(positionSS, depth, 1);
    float4 ws = mul(cameraToWorld, cs);
    //float3 position = ws.xyz / ws.w;
      
    float3 N = (float3)0;
    float3 roughness = (float3)0;
                
    NormalData normalData;
    DecodeFromNormalBuffer(positionSS, normalData);
    N = normalData.normalWS * depth;
    roughness = normalData.perceptualRoughness;
    
    Ray r;
    r.a = ws;
    r.direction = N; 
    r.invDir = 1 / N;
    r.energy = (float3)1;//change this according to the material
    
    for(uint i = 0; i < 4; ++i)
    {
        hit.alpha = cameraPlanes.y + 1;
        
        Trace(r, hit);
        color += r.energy * Shade(r, hit);
        
        if(!any(r.energy))
            break;
    }
    
    texOut[id.xy] = float4(color, 1.0f);
}*/
